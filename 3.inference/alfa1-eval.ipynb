{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, используя тестовые датасеты и 8-фолдовую модель, делаем предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" \n",
    "    iterate through all the columns of a dataframe and \n",
    "    modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(('Memory usage of dataframe is {:.2f}' \n",
    "                     'MB').format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max <\\\n",
    "                  np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max <\\\n",
    "                   np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max <\\\n",
    "                   np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max <\\\n",
    "                   np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max <\\\n",
    "                   np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max <\\\n",
    "                   np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(('Memory usage after optimization is: {:.2f}' \n",
    "                              'MB').format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \n",
    "                                             / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb = pd.read_csv('../input/alfabattle-1-stat/alfa1_df_valid6.csv')\n",
    "df_test_lgb = pd.read_csv('../input/alfabattle-1-stat-test/df_test_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb.fillna('nothing', inplace=True)\n",
    "df_test_lgb.fillna('nothing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb = reduce_mem_usage(df_valid_lgb)\n",
    "df_test_lgb = reduce_mem_usage(df_test_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(df_valid_lgb['lag_1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb_exp = pd.read_csv('../input/alfabattle-1-stat4/alfa1_df_valid10.csv')\n",
    "df_test_lgb_exp = pd.read_csv('../input/alfabattle-1-stat-test/df_test_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb_exp = reduce_mem_usage(df_valid_lgb_exp)\n",
    "df_test_lgb_exp = reduce_mem_usage(df_test_lgb_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb_exp1 = pd.read_csv('../input/alfabattle-1-stat5/alfa1_df_valid11.csv')\n",
    "df_test_lgb_exp1 = pd.read_csv('../input/alfabattle-1-stat-test/df_test_exp1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb_exp1 = reduce_mem_usage(df_valid_lgb_exp1)\n",
    "df_test_lgb_exp1 = reduce_mem_usage(df_test_lgb_exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb_exp2 = pd.read_csv('../input/alfabattle-1-stat6/alfa1_df_valid12.csv')\n",
    "df_test_lgb_exp2 = pd.read_csv('../input/alfabattle-1-stat-test/df_test_exp2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb_exp2 = reduce_mem_usage(df_valid_lgb_exp2)\n",
    "df_test_lgb_exp2 = reduce_mem_usage(df_test_lgb_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_lgb = df_valid_lgb_exp.drop(['client_pin', 'lag_1', 'lag_2', 'weight'], axis=1).columns\n",
    "aug_lgb1 = df_valid_lgb_exp1.drop(['client_pin', 'lag_1', 'lag_2', 'weight'], axis=1).columns\n",
    "aug_lgb2 = df_valid_lgb_exp2.drop(['client_pin', 'lag_1', 'lag_2', 'weight'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb[aug_lgb] = df_valid_lgb_exp[aug_lgb]\n",
    "df_test_lgb[aug_lgb] = df_test_lgb_exp[aug_lgb]\n",
    "\n",
    "df_valid_lgb[aug_lgb1] = df_valid_lgb_exp1[aug_lgb1]\n",
    "df_test_lgb[aug_lgb1] = df_test_lgb_exp1[aug_lgb1]\n",
    "\n",
    "df_valid_lgb[aug_lgb2] = df_valid_lgb_exp2[aug_lgb2]\n",
    "df_test_lgb[aug_lgb2] = df_test_lgb_exp2[aug_lgb2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_lgb['class_weight'] = 1\n",
    "df_test_lgb['class_weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_valid = []\n",
    "for k in range(df_valid_lgb.shape[0]):\n",
    "    a = np.argmax(lgb_proba_valid[k,])\n",
    "    lgb_valid.append(a)\n",
    "\n",
    "lgb_test = []\n",
    "for k in range(df_test_lgb.shape[0]):\n",
    "    a = np.argmax(lgb_proba_test[k,])\n",
    "    lgb_test.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "to_drop.append('lag_1')\n",
    "to_drop.append('client_pin')\n",
    "to_drop.append('weight')\n",
    "to_drop.append('class_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 8\n",
    "lgb_proba_valid = np.zeros((df_valid_lgb.shape[0], 10))\n",
    "lgb_proba_test = np.zeros((df_test_lgb.shape[0], 10))\n",
    "for i in range(n_splits):\n",
    "    with open(f'../input/lgb-models/lgb_model8_fold{i}.pkl', 'rb') as fin:\n",
    "        model_lgb = pickle.load(fin)\n",
    "    lgb_proba_valid += model_lgb.predict(df_valid_lgb.drop(to_drop, axis=1)) / n_splits\n",
    "    lgb_proba_test += model_lgb.predict(df_test_lgb.drop(to_drop, axis=1)) / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_lgb['lag_1'] = le1.inverse_transform(lgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('../input/alfabattle1/alfabattle2_abattle_sample_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.drop(['prediction'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.merge(df_test_lgb[['client_pin', 'lag_1']].rename({'lag_1':'prediction'}, axis=1), how='left', on='client_pin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv('alfa1_lgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
